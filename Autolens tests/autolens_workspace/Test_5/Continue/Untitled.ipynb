{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# \n",
    "# ## Attention!\n",
    "# ### This code runs in MPI mode.\n",
    "# \n",
    "# \n",
    "# Trying to recover the input values of the simulation. The free parameters are:\n",
    "#    - One ML, One beta, qinc, mbh, kappa_s, qDm, mag_shear, phi_shear and gamma.\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#Control time packages\n",
    "import time\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "#MPI\n",
    "from schwimmbad import MPIPool\n",
    "\n",
    "#General packages\n",
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Constants and usefull packages\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "from astropy.cosmology import z_at_value\n",
    "from astropy.constants import G, M_sun, c\n",
    "import astropy.units as u\n",
    "\n",
    "#Autolens Model packages\n",
    "import autolens as al\n",
    "import autolens.plot as aplt\n",
    "\n",
    "#My Emcee for Pyautolens\n",
    "import My_Autolens\n",
    "\n",
    "data_folder = \"/home/carlos/Documents/GitHub/Master-Degree/Autolens tests/autolens_workspace/Test_5/Simulation_Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Reading MGE inputs\n",
    "surf_lum, sigma_lum, qobs_lum = np.loadtxt(\"Input/JAM_Input.txt\", unpack=True)      #MGE decomposition\n",
    "surf_dm, sigma_dm , qobs_dm   = np.loadtxt(\"Input/eNFW.txt\", unpack=True)            #DM component\n",
    "\n",
    "## Models inicialization\n",
    "\n",
    "\"\"\"\n",
    "    To inicialize the model, we set some random values for the parameters. But it's only necessary for initialize the model. During the non-linear search, this values will be updated constantly until the best fit.\n",
    "\"\"\"  \n",
    "#Only for lensing modelling \n",
    "z_l    = 0.299                                                         #Lens Redshift\n",
    "z_s    = 4.100                                                         #Source Redshift \n",
    "D_l    = cosmo.angular_diameter_distance(z_l).value                    #Distance to lens [Mpc] \n",
    "mbh    = 1e9                                                           #mass of black hole [log10(M_sun)]\n",
    "kappa_ = 0.075                                                         #kappa_s of DM profile\n",
    "ml     = 7.00                                                          #mass to light ratio\n",
    "r_s    = 11.5                                                          #scale radius [arcsec]\n",
    "shear_comp = al.convert.shear_elliptical_comps_from(magnitude=0.02, phi=88) #external shear\n",
    "\n",
    "\n",
    "#Autolens Data\n",
    "imaging = al.Imaging.from_fits(\n",
    "        image_path=f\"{data_folder}/arcs_simulation.fits\",\n",
    "        noise_map_path=f\"{data_folder}/noise_simulation.fits\",\n",
    "        psf_path=f\"{data_folder}/psf_simulation.fits\",\n",
    "        pixel_scales=0.1,\n",
    "    )\n",
    "\n",
    "mask        = al.Mask.from_fits( file_path=f\"{data_folder}/new_mask.fits\", hdu=1, \n",
    "                                pixel_scales=imaging.pixel_scales)\n",
    "\n",
    "masked_image = al.MaskedImaging(imaging=imaging, mask=mask, inversion_uses_border=True)   #Masked image\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------#\n",
    "# PYAUTOLENS MODEL\n",
    "#MGE mass profile\n",
    "mass_profile = al.mp.MGE()    #Mass class\n",
    "\n",
    "ell_comps    = al.convert.elliptical_comps_from(axis_ratio=qobs_dm[0], phi=0.0) #Elliptical components in Pyautolens units\n",
    "eNFW         = al.mp.dark_mass_profiles.EllipticalNFW(kappa_s=kappa_, elliptical_comps=ell_comps ,scale_radius=r_s) #Analytical eNFW profile\n",
    "\n",
    "\n",
    "#Components\n",
    "#Do not include MGE DM component here\n",
    "mass_profile.MGE_comps(z_l=z_l, z_s=z_s, \n",
    "                       surf_lum=surf_lum, sigma_lum=sigma_lum, qobs_lum=qobs_lum, ml=ml, mbh=mbh) \n",
    "mass_profile.Analytic_Model(eNFW)  #Include Analytical NFW\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------#\n",
    "#Emcee Model\n",
    "emcee_model = My_Autolens.Models(mass_profile=mass_profile, masked_imaging=masked_image, quiet=True)\n",
    "emcee_model.include_DM_analytical(eNFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Input/Lens_Simulation.h5\"\n",
    "read = emcee.backends.HDFBackend(filename)\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "nwalkers, ndim = read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves=[(emcee.moves.DEMove(gamma0=0.063), 0.90), (emcee.moves.DEMove(), 0.10)]\n",
    "    #Initialize the new sampler\n",
    "new_sampler = emcee.EnsembleSampler(nwalkers, ndim, emcee_model,backend=backend, moves=moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = new_sampler.get_last_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sampler.reset()\n",
    "backend.reset(nwalkers=nwalkers, ndim=ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/500000 [10:10<8589:44:28, 61.85s/it]/home/carlos/anaconda3/lib/python3.7/site-packages/emcee/autocorr.py:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acf /= acf[0]\n",
      "/home/carlos/anaconda3/lib/python3.7/site-packages/emcee/autocorr.py:41: RuntimeWarning: invalid value encountered in less\n",
      "  m = np.arange(len(taus)) < c * taus\n",
      "/home/carlos/anaconda3/lib/python3.7/site-packages/emcee/autocorr.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  flag = tol * tau_est > n_t\n",
      "/home/carlos/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in less\n",
      "/home/carlos/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/500000 [19:19<8202:05:27, 59.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/500000 [29:47<8759:13:29, 63.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/500000 [40:11<8720:39:09, 62.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/500000 [46:35<8909:17:59, 64.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception ocurres in Pyautolens_log_likelihood().\n",
      "An exception ocurres in Pyautolens_log_likelihood().\n",
      "An exception ocurres in Pyautolens_log_likelihood().\n"
     ]
    }
   ],
   "source": [
    "nsteps = 500000                          #Number of walkes \n",
    "\n",
    " # We'll track how the average autocorrelation time estimate changes\n",
    "index = 0\n",
    "autocorr = np.empty(nsteps)\n",
    " # This will be useful to testing convergence\n",
    "old_tau = np.inf\n",
    " # This saves how many walkers have been accepted in the last 100 steps\n",
    "old_accp = np.zeros(nwalkers,)\n",
    "\n",
    "\n",
    "# Now we'll sample for up to max_n steps\n",
    "start = time.time()\n",
    "global_time = time.time()\n",
    "\n",
    "\n",
    "for sample in new_sampler.sample(state, iterations=nsteps, progress=True):\n",
    "    # Only check convergence every 100 steps\n",
    "    if new_sampler.iteration % 10:\n",
    "        continue\n",
    "    print(\"\\n\")\n",
    "    print(\"##########################\")\n",
    "\n",
    "    #Compute how many walkes have been accepted during the last 100 steps\n",
    "\n",
    "    new_accp = new_sampler.backend.accepted             #Total number of accepted\n",
    "    old_accp = new_accp - old_accp                  #Number of accepted in the last 100 steps\n",
    "    mean_accp_100 = np.mean(old_accp/float(100))    #Mean accp fraction of last 100 steps\n",
    "\n",
    "    #Update a table output with acceptance\n",
    "    table = np.loadtxt(\"Output_LogFile.txt\")\n",
    "\n",
    "    iteration = new_sampler.iteration\n",
    "    accept = np.mean(new_sampler.acceptance_fraction)\n",
    "    total_time = time.time() - global_time\n",
    "    upt = np.column_stack([iteration, accept, total_time, mean_accp_100])\n",
    "\n",
    "    np.savetxt('Output_LogFile.txt', np.vstack([table, upt]),\n",
    "                            fmt=b'\t%i\t %e\t\t\t %e             %e', \n",
    "                        header=\"Output table for the combined model: Dynamic.\\n Iteration\t Mean acceptance fraction\t Processing Time    Last 100 Mean Accp. Fraction\")\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = new_sampler.get_autocorr_time(tol=0)\n",
    "    autocorr[index] = np.mean(tau)\n",
    "    index += 1\n",
    "\n",
    "    # Check convergence\n",
    "    converged = np.all(tau * 100 < new_sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    if converged:\n",
    "        if 0.2 < accept < 0.35:\n",
    "            break\n",
    "    old_tau = tau\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('\\n')\n",
    "print(\"Final\")\n",
    "multi_time = end - start\n",
    "print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
