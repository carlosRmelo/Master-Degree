{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from os import path\n",
    "from time import perf_counter as clock\n",
    "\n",
    "from astropy.io import fits\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ppxf as ppxf_package\n",
    "from ppxf.ppxf import ppxf\n",
    "import ppxf.ppxf_util as util\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppxf_dir   = \"/home/carlos/Downloads/BADASS3-master/badass_data_files/indo_us_library/\"\n",
    "spec_path  = \"/home/carlos/Desktop/pPXF(SDP)/Data/Voronoi20/Binned_Spec/\"\n",
    "save_paths = glob.glob(\"/home/carlos/Desktop/pPXF(SDP)/Data/Voronoi20/Bootstrapping/Bin*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit(spec_name, galboots=None, bootstrapping=False):\n",
    "    # Read a galaxy spectrum and define the wavelength range\n",
    "    #\n",
    "    file = spec_path + spec_name + \".fits\"\n",
    "    hdu = fits.open(file)\n",
    "    gal_lin = hdu[1].data\n",
    "    h1 = hdu[1].header\n",
    "\n",
    "    lamRange1 = h1['CRVAL1'] + np.array([0., h1['CDELT1']*(h1['NAXIS1'] - 1)])\n",
    "    FWHM_gal = 2.71  # SAURON has an instrumental resolution FWHM of 4.2A.\n",
    "\n",
    "    #READING THE VARIANCE/LENDO A VARIÂNCIA DO ESPECTRO\n",
    "\n",
    "    var = hdu[2].data     #Read the variance/Lendo a variância\n",
    "    h_var = hdu[2].header #Read the variance header/Lendo o header da variância\n",
    "    lamRange_var = h_var['CRVAL1'] + np.array([0.,h_var['CDELT1']*(h_var['NAXIS1']-1)])\n",
    "\n",
    "    # If the galaxy is at significant redshift, one should bring the galaxy\n",
    "    # spectrum roughly to the rest-frame wavelength, before calling pPXF\n",
    "    # (See Sec2.4 of Cappellari 2017). In practice there is no\n",
    "    # need to modify the spectrum in any way, given that a red shift\n",
    "    # corresponds to a linear shift of the log-rebinned spectrum.\n",
    "    # One just needs to compute the wavelength range in the rest-frame\n",
    "    # and adjust the instrumental resolution of the galaxy observations.\n",
    "    # This is done with the following three commented lines:\n",
    "    #\n",
    "    z = 0.299  # Initial redshift estimate of the galaxy\n",
    "    #z = 1.23 # Initial estimate of the galaxy redshift\n",
    "    lamRange1 = lamRange1/(1+z) # Compute approximate restframe wavelength range\n",
    "    FWHM_gal = FWHM_gal/(1+z)   # Adjust resolution in Angstrom\n",
    "    lamRange_var = lamRange_var/(1+z)\n",
    "    z = 0.00\n",
    "\n",
    "    galaxy, logLam1, velscale = util.log_rebin(lamRange1, gal_lin)\n",
    "    if bootstrapping is True:\n",
    "        galaxy = galboots\n",
    "        \n",
    "    median_galaxy = np.median(galaxy)\n",
    "    galaxy = galaxy/median_galaxy  # Normalize spectrum to avoid numerical issues\n",
    "    lam = np.exp(logLam1)\n",
    "\n",
    "\n",
    "    erro = np.sqrt(var) #1-sigma error from variance/1-sigma erro da variância\n",
    "    erro, loglam_var, velscale_var = util.log_rebin(lamRange_var, erro)\n",
    "    noise = erro/median_galaxy         #Normalizing the error/Normalizando o erro    \n",
    "\n",
    "    # Read the list of filenames from the Single Stellar Population library\n",
    "    # by Vazdekis (2010, MNRAS, 404, 1639) http://miles.iac.es/. A subset\n",
    "    # of the library is included for this example with permission\n",
    "    vazdekis = glob.glob(ppxf_dir + '/*.fits')\n",
    "    FWHM_tem = 1.35  # Indu spectra  resolution\n",
    "    velscale_ratio = 2  # adopts 2x higher spectral sampling for templates than for galaxy\n",
    "    \n",
    "    \n",
    "    # Extract the wavelength range and logarithmically rebin one spectrum\n",
    "    # to a velocity scale 2x smaller than the SAURON galaxy spectrum, to determine\n",
    "    # the size needed for the array which will contain the template spectra.\n",
    "    #\n",
    "    hdu = fits.open(vazdekis[0])\n",
    "    ssp = hdu[0].data\n",
    "    h2 = hdu[0].header\n",
    "    lamRange2 = h2['CRVAL1'] + np.array([0., h2['CDELT1']*(h2['NAXIS1'] - 1)])\n",
    "    sspNew, logLam2, velscale_temp = util.log_rebin(lamRange2, ssp, velscale=velscale/velscale_ratio)\n",
    "    templates = np.empty((sspNew.size, len(vazdekis)))\n",
    "    \n",
    "    # Convolve the whole Vazdekis library of spectral templates\n",
    "    # with the quadratic difference between the SAURON and the\n",
    "    # Vazdekis instrumental resolution. Logarithmically rebin\n",
    "    # and store each template as a column in the array TEMPLATES.\n",
    "\n",
    "    # Quadratic sigma difference in pixels Vazdekis --> SAURON\n",
    "    # The formula below is rigorously valid if the shapes of the\n",
    "    # instrumental spectral profiles are well approximated by Gaussians.\n",
    "    #\n",
    "    FWHM_dif = np.sqrt(FWHM_gal**2 - FWHM_tem**2)\n",
    "    sigma = FWHM_dif/2.355/h2['CDELT1']  # Sigma difference in pixels\n",
    "\n",
    "    for j, file in enumerate(vazdekis):\n",
    "        hdu = fits.open(file)\n",
    "        ssp = hdu[0].data\n",
    "        ssp = ndimage.gaussian_filter1d(ssp, sigma)\n",
    "        sspNew, logLam2, velscale_temp = util.log_rebin(lamRange2, ssp, velscale=velscale/velscale_ratio)\n",
    "        templates[:, j] = sspNew/np.median(sspNew)  # Normalizes templates\n",
    "        \n",
    "        # The galaxy and the template spectra do not have the same starting wavelength.\n",
    "    # For this reason an extra velocity shift DV has to be applied to the template\n",
    "    # to fit the galaxy spectrum. We remove this artificial shift by using the\n",
    "    # keyword VSYST in the call to PPXF below, so that all velocities are\n",
    "    # measured with respect to DV. This assume the redshift is negligible.\n",
    "    # In the case of a high-redshift galaxy one should de-redshift its\n",
    "    # wavelength to the rest frame before using the line below (see above).\n",
    "    #\n",
    "    c = 299792.458\n",
    "    dv = (np.mean(logLam2[:velscale_ratio]) - logLam1[0])*c  # km/s\n",
    "\n",
    "    goodPixels = util.determine_goodpixels(logLam1, lamRange2, z)\n",
    "    # Here the actual fit starts. The best fit is plotted on the screen.\n",
    "# Gas emission lines are excluded from the pPXF fit using the GOODPIXELS keyword.\n",
    "\n",
    "    vel = c*np.log(1 + z)   # eq.(8) of Cappellari (2017)\n",
    "    start = [vel, 200.]  # (km/s), starting guess for [V, sigma]\n",
    "\n",
    "\n",
    "    pp = ppxf(templates, galaxy, noise, velscale, start,lam=lam,\n",
    "              goodpixels=goodPixels, plot=True, moments=2,quiet=True,\n",
    "              degree=6, vsyst=dv, velscale_ratio=velscale_ratio, bias=0.)\n",
    "    #print(\"Formal errors:\")\n",
    "    #print(\"     dV    dsigma   dh3      dh4\")\n",
    "    #print(\"\".join(\"%8.2g\" % f for f in pp.error*np.sqrt(pp.chi2)))\n",
    "    hdu.close()\n",
    "    out = pp.bestfit, pp.galaxy, pp.sol, pp.noise, goodPixels\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_fig(save_path, spec_name, it,\n",
    "                                 galboots=None):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if galboots is not None:\n",
    "        out = _fit(spec_name, galboots=galboots, bootstrapping=True)\n",
    "    else:\n",
    "        out = _fit(spec_name)\n",
    "    sols = out[2]\n",
    "    \n",
    "    textx = 500\n",
    "    texty = 1.2\n",
    "    sols = out[2]\n",
    "    textx = [375, 385]\n",
    "    texty = 1.4\n",
    "    texty2 = 1.3\n",
    "    fs = 20\n",
    "    plt.text(textx[0], texty, r'V [km/s]', size=fs)\n",
    "    plt.text(textx[1], texty, r'$\\sigma$ [km/s]', size=fs)\n",
    "\n",
    "    plt.text(textx[0], texty2, str(int(sols[0])), size=fs)\n",
    "    plt.text(textx[1], texty2, str(int(sols[1])), size=fs)\n",
    "\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.savefig(save_path+spec_name+'_iteration_%d'%it,dpi=100)\n",
    "    plt.close()\n",
    "    \n",
    "    return out\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def bootstrap(nit, save_path, spec_name):\n",
    "# basically bootstrap the noise!\n",
    "    # Do one fit with flat noise, then save the best fit spectrum and the residuals.\n",
    "    # Then, iterate ~200 times. For these iterations, set bias = 0.0. Each iteration, for each pixel, use the spectrum\n",
    "    # value as the center of a gaussian and use the residuals at that pixel value as the width of the gaussian. Draw\n",
    "    # from the resultant distribution to make the new noise. For each iteration, save the output V, sigma, h3, h4, and\n",
    "    # print each spectrum so that we can see it evolving (it should look more like a real spectrum, rather than smooth\n",
    "    # curve without lines)\n",
    "    out = bootstrap_fig(save_path, spec_name, 0)\n",
    "    sols = out[2]\n",
    "    \n",
    "    sol_matrix = np.zeros(shape=(2, nit))\n",
    "    resid = out[1] - out[0]  # galaxy - bestfit = resid, from ppxf()\n",
    "    #resid = resid[out[4]]    # resid[goodPixels]\n",
    "    orig_noise = out[3]      # original noise of spectrum\n",
    "    #orig_noise = orig_noise[out[4]] # original_noise[goodPixels]\n",
    "    \n",
    "    std_dev = np.sqrt(orig_noise**2 + resid**2)  # the residual noise and spectral noise added in quadrature\n",
    "    bfit = out[0]\n",
    "    orig = out[2]\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(nit):\n",
    "        #print(counter)\n",
    "        new_gal = np.random.normal(loc=bfit, scale=std_dev)\n",
    "        \n",
    "        counter += 1\n",
    "        new_gal = np.asarray(new_gal)\n",
    "        #print(new_gal.shape)\n",
    "\n",
    "        out = bootstrap_fig(save_path, spec_name, counter, galboots=new_gal)\n",
    "        sols = out[2]\n",
    "        sol_matrix[:, counter - 1] = sols  # save solutions\n",
    "        plt.close(\"all\")\n",
    "        plt.clf()\n",
    "        \n",
    "    \n",
    "    return sol_matrix, orig\n",
    "\n",
    "def plot_boots(nit, sol_matrix, orig_fit,\n",
    "                  save_path):\n",
    "    iters=nit\n",
    "    fig = plt.figure(figsize=(1.4, 3.8))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "    axes = [ax1, ax2]\n",
    "    labels = [r'V', r'$\\sigma$',]\n",
    "    for i in range(len(sol_matrix)):  # 4\n",
    "        percs = np.percentile(sol_matrix[i], [0.3, 2.4, 16.0, 50.0, 84.0, 97.6, 99.7])  # median, 1,2,3 sigma\n",
    "        t_x = min(sol_matrix[i])\n",
    "        t_y1 = 0.02\n",
    "        t_y2 = 0.03\n",
    "        t_y3 = 0.04\n",
    "        # axes[i].text(t_x, t_y3,)\n",
    "\n",
    "        axes[i].axvline(x=orig_fit[i], color='k', linestyle='--', lw=2, label='Original fit')\n",
    "\n",
    "        axes[i].hist(sol_matrix[i], bins=50, histtype=\"step\", weights=[1. / iters] * len(sol_matrix[i]),\n",
    "                     color='k', lw=2, label=labels[i])\n",
    "        axes[i].axvline(x=percs[3], color='b', linestyle='--', lw=2, label='Median')\n",
    "        axes[i].axvline(x=np.mean(sol_matrix[i]), color='b', ls='-', lw=2, label='Mean')\n",
    "\n",
    "        axes[i].axvspan(percs[0], percs[6], color='b', alpha=0.1)  # 3 sigma\n",
    "        axes[i].axvspan(percs[1], percs[5], color='b', alpha=0.1)  # 2 sigma\n",
    "        axes[i].axvspan(percs[2], percs[4], color='b', alpha=0.1)  # 1 sigma\n",
    "        axes[i].legend(numpoints=1, loc='upper left', prop={'size': 10})\n",
    "\n",
    "        fig.set_size_inches(18.5, 6.5)\n",
    "        # plt.text()\n",
    "\n",
    "        #print(percs)\n",
    "        #print(orig, 'orig')\n",
    "    axes[0].set_xlabel(r'V [km/s]')\n",
    "    axes[1].set_xlabel(r'$\\sigma$ [km/s]')\n",
    "    plt.savefig (save_path+'Resume_%d_iterations'%iters)  # , dpi=500)\n",
    "    #plt.show()\n",
    "    plt.close(\"all\")\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nit = 200\n",
    "for i in range(len(save_paths)):\n",
    "    spec_name = (\"Bin\"+save_paths[i][len(save_paths[i])-2])\n",
    "    sol_matrix, orig_fit = bootstrap(nit=nit, save_path=save_paths[i], spec_name=spec_name)\n",
    "    plot_boots(nit=nit, sol_matrix=sol_matrix, orig_fit=orig_fit, save_path=save_paths[i])\n",
    "    plt.clf()\n",
    "    np.savetxt(save_paths[i]+\"Sol_Matrix.txt\", np.column_stack([sol_matrix[0],sol_matrix[1]]),\n",
    "               header=\"Vel [km/s] \\t Disp [km/s]\",\n",
    "               fmt=\"%.5e \\t %.5e\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
