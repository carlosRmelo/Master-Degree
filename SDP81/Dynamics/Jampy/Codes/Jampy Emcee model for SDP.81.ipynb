{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Carlos Roberto de Melo\n",
    "    \n",
    "Date: 12/13/2020\n",
    "    \n",
    "Goal: Jampy Emcee model for SDP.81.\n",
    "Here we assume a dark matter component described by a pseudo NFW profile, a Gaussian ML ratio. Beside that, we let free the super massive black hole mass, the anisotropy parameter an the inclination.\n",
    "\n",
    "The pseudo-NFW parameter has two free parameters: intensity (i.e $\\rho_s$) and the axial ratio. While the gaussian ML has three parameters, the central mass-to-light ratio, the sigma gaussian (named delta here), and the lower value of the ML.\n",
    "\n",
    "We assume flat prior for all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packeges\n",
    "\n",
    "import numpy as np\n",
    "from My_Jampy import JAM\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import os\n",
    "\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "y_px, x_px, vrms, erms = np.loadtxt('pPXF_rot_data.txt', unpack=True)                  #pPXF\n",
    "surf_star_dat, sigma_star_dat, qstar_dat = np.loadtxt('JAM_Input.txt', unpack=True)    #photometry\n",
    "surf_DM_dat, sigma_DM_dat, qDM_dat  = np.loadtxt('pseudo-DM Input.txt', unpack=True)    #DM\n",
    "\n",
    "\n",
    "muse_normpsf, muse_sigmapsf = np.loadtxt(\"MUSE_Psf_model.txt\", unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------- EMCEE -----------------------------------------------------#\n",
    "\n",
    "\n",
    "### Priors#--------------------------------------- EMCEE -----------------------------------------------------#\n",
    "\n",
    "\n",
    "### Priors# parameter boundaries. [lower, upper]\n",
    "boundary = {'inc': [70, 120], 'beta': [-5, 5], 'ml0': [0.5, 15], 'delta': [0.5, 2], 'lower': [0, 1],\n",
    "            'log_mbh':[7, 11], 'qDM': [0.15, 1], 'log_rho_s':[6, 13] }\n",
    "\n",
    "\n",
    "def gaussian_ml(sigma, delta, ml0=1.0, lower=0.0):\n",
    "    '''\n",
    "    Create a M*L gradient\n",
    "    sigma: Gaussian sigma [arcsec]\n",
    "    delta: Gradient value\n",
    "    ml0: Central stellar mass to light ratio\n",
    "    lower: the ratio between the central and the outer most M*/L\n",
    "    '''\n",
    "\n",
    "    sigma = np.atleast_1d(sigma)\n",
    "    sigma = sigma - sigma[0]\n",
    "    ML = ml0 * (lower + (1-lower)*np.exp(-0.5 * (sigma * delta)**2))\n",
    "    \n",
    "    return ML\n",
    "\n",
    "\n",
    "def check_Deprojected_axial(parsDic):\n",
    "    inc = np.radians(parsDic['inc'])\n",
    "    #Stellar\n",
    "    qintr_star = qstar_dat**2 - np.cos(inc)**2\n",
    "    if np.any(qintr_star <= 0):\n",
    "        return -np.inf\n",
    "    \n",
    "    qintr_star = np.sqrt(qintr_star)/np.sin(inc)\n",
    "    if np.any(qintr_star <= 0.05):\n",
    "        return -np.inf\n",
    "    \n",
    "        #DM\n",
    "    qintr_DM = parsDic['qDM']**2 - np.cos(inc)**2\n",
    "    if qintr_DM <= 0:\n",
    "        return -np.inf\n",
    "    \n",
    "    qintr_DM = np.sqrt(qintr_DM)/np.sin(inc)\n",
    "    if qintr_DM <= 0.05:\n",
    "        return -np.inf\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def check_boundary(parsDic):\n",
    "    \"\"\"\n",
    "        Check whether parameters are within the boundary limits\n",
    "        input\n",
    "            parsDic: parameter dictionary {'paraName', value}\n",
    "        output\n",
    "            -np.inf or 0.0\n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    #Check if beta is ok\n",
    "\n",
    "    #Avoid beta[i] == 1, because this could cause problems\n",
    "    if any(parsDic['beta'] == 1):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #Check beta boundary\n",
    "    for i in range(len(parsDic['beta'])):\n",
    "        if boundary['beta'][0] < parsDic['beta'][i] < boundary['beta'][1] :\n",
    "            pass\n",
    "        else:\n",
    "            return -np.inf\n",
    "\n",
    "\n",
    "    #Check if deprojected axial ratio is ok  (q' <=0 or q' <= 0.05) for the dynamical model.\n",
    "    if not np.isfinite(check_Deprojected_axial(parsDic)):\n",
    "        return -np.inf\n",
    "\n",
    "    #Check if the others parameters are within the boundary limits\n",
    "    keys = set(parsDic.keys())\n",
    "    excludes = set(['beta'])  #Exclude beta and ml, because we already verify above\n",
    "\n",
    "\n",
    "    for keys in keys.difference(excludes):\n",
    "        if boundary[keys][0] < parsDic[keys] < boundary[keys][1]:\n",
    "            pass\n",
    "        else:\n",
    "            return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def log_prior(parsDic):\n",
    "    '''\n",
    "    Calculate the prior lnprob\n",
    "    input\n",
    "      parsDic: parameter dictionary {'paraName', value}\n",
    "    output\n",
    "      lnprob\n",
    "    '''\n",
    "    \n",
    "    rst = 0\n",
    "    \"\"\"\n",
    "    The lines above is only for doble check, because we are assuming flat prior for all parameters Once we got here, all values ​​have already been accepted, so just return 0.0 for one of them\n",
    "    \"\"\"\n",
    "\n",
    "    rst += 0.0     #ml0\n",
    "    rst += 0.0     #beta\n",
    "    rst += 0.0     #inc\n",
    "    rst += 0.0     #log_mbh\n",
    "    rst += 0.0     #qDM\n",
    "    rst += 0.0     #log_rho_s\n",
    "    rst += 0.0     #delta\n",
    "    rst += 0.0     #lower\n",
    "    \n",
    "    return rst\n",
    "\n",
    "\n",
    "def Updt_JAM(parsDic):\n",
    "    '''\n",
    "       Update the dynamical mass model\n",
    "    input\n",
    "      parsDic: parameter dictionary {'paraName', value}\n",
    "    '''\n",
    "    surf_DM_model = surf_DM_dat*(10**parsDic['log_rho_s'])       #DM mass surface density\n",
    "    qDM_model = np.ones(qDM_dat.shape)*parsDic['qDM']            #DM axial ratio\n",
    "    beta_model = np.array(parsDic['beta'])                       #anisotropy parameter\n",
    "    mbh_model = 10**parsDic['log_mbh']                           #BH mass\n",
    "    \n",
    "    #mass-to-light update \n",
    "    ml_model = gaussian_ml(sigma=sigma_star_dat, delta=parsDic['delta'],\n",
    "                           ml0=parsDic['ml0'], lower=parsDic['lower'])\n",
    "    \n",
    "\n",
    "\n",
    "    #Model Updt\n",
    "    Jampy_model.upt(surf_dm=surf_DM_model, qobs_dm=qDM_model, inc=parsDic['inc'],\n",
    "                     ml=ml_model, beta=parsDic['beta'], mbh=mbh_model)\n",
    "    \n",
    "def JAM_log_likelihood(parsDic):\n",
    "    \"\"\"\n",
    "        Perform JAM modeling and return the chi2\n",
    "    \"\"\"\n",
    "    \n",
    "    Updt_JAM(parsDic)               #Updt values for each iteration\n",
    "    \n",
    "    rmsModel, ml, chi2, chi2T = Jampy_model.run()\n",
    "    return -0.5 * chi2T\n",
    "\n",
    "def log_probability(pars):\n",
    "    \"\"\"\n",
    "        Log-probability function for whole model.\n",
    "        input:\n",
    "            pars: current values in the Emcee sample.\n",
    "        output:\n",
    "            log probability for the combined model.\n",
    "    \"\"\"\n",
    "\n",
    "    (ml0, delta, lower, b1, b2, b3, b4, b5, b6, b7, b8, inc, log_mbh, qDM, log_rho_s) = pars\n",
    "    \n",
    "\n",
    "    \n",
    "    beta =  np.array([b1, b2, b3, b4, b5, b6, b7, b8])\n",
    "    parsDic = {'ml0': ml0, 'delta': delta, 'lower':lower, 'inc': inc, 'qDM': qDM, 'log_rho_s': log_rho_s,\n",
    "               'log_mbh': log_mbh, 'beta': beta}\n",
    "    \n",
    "    #Checking boundaries\n",
    "    if not np.isfinite(check_boundary(parsDic)):\n",
    "        return -np.inf\n",
    "    #calculating the log_priors\n",
    "    lp = log_prior(parsDic)\n",
    "\n",
    "    return lp + JAM_log_likelihood(parsDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the model.\n",
    "\n",
    "#Galaxy/telescope intrinsic parameters\n",
    "distance = cosmo.angular_diameter_distance(0.299).value     #Angular diameter distance [Mpc]\n",
    "pixsize=0.2                                                 #pixscale of IFU [arcsec/px]\n",
    "inc = 85                                                    #Inclination [deg]\n",
    "log_mbh = 8                                                 #Log Mass of black hole [log(M_sun)]\n",
    "beta0 = np.ones_like(surf_star_dat)*0.3                     #Anisotropy parameter, one for each gaussian component\n",
    "log_rho_s = 8                                               #Log Dark Matter intensity component [log(M_sun/pc²)]\n",
    "ML0 = gaussian_ml(sigma=sigma_star_dat, \n",
    "                      delta=0.5, ml0=10, lower=0.4)         #Gaussian Mass-to-light ratio [M_sun/L_sun]\n",
    "\n",
    "#Create the model\n",
    "Jampy_model = JAM(ybin=y_px, xbin=x_px,inc=inc, distance=distance, mbh= 10**log_mbh,\n",
    "                  rms=vrms, erms=erms, beta=beta0, normpsf=muse_normpsf, sigmapsf=muse_sigmapsf, pixsize=pixsize)\n",
    "\n",
    "#Add Luminosity component\n",
    "Jampy_model.luminosity_component(surf_lum=surf_star_dat, sigma_lum=sigma_star_dat,\n",
    "                                    qobs_lum=qstar_dat, ml=ML0)\n",
    "\n",
    "#Add Dark Matter component\n",
    "Jampy_model.DM_component(surf_dm=(10**log_rho_s)*surf_DM_dat, sigma_dm=sigma_DM_dat, qobs_dm=qDM_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic anisotropy profile from a Schwarzschild model.\n",
    "# The anisotropy varies smoothly between the following three regimes:\n",
    "# 1. beta = -1 for R < 1\"\n",
    "# 2. beta = 0.3 for 1\" < R < 30\"\n",
    "# 3. beta = -0.2 for R > 30\"\n",
    "#\n",
    "beta0 = np.empty_like(sigma_star_dat)\n",
    "beta0[sigma_star_dat <= 1] = -1.0\n",
    "beta0[(sigma_star_dat > 1) & (sigma_star_dat <= 30)] = 0.3\n",
    "beta0[sigma_star_dat > 30] = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------EMCEE--------------------------#\n",
    "\n",
    "#Initial positions\n",
    "\"\"\"\n",
    "    Pay close attention to the order in which the components are added. \n",
    "    They must follow the log_probability unpacking order.\n",
    "\"\"\"\n",
    "\n",
    "ml_init = np.array([10, 0.7, 0.4])                #Parameters of gaussian ML [ml0, delta, lower]\n",
    "beta_init = beta0                                 #Anisotropy parameters \n",
    "inc_init = np.array([85])                         #Inclination in deg\n",
    "log_mbh_init = np.array([8])                      #Log mass of SMBH\n",
    "qDM_init = np.array([0.5])                        #Scalar describing the axial ratio of DM component\n",
    "log_rho_s_init = np.array([8])                    #Log intensity of pseudo-NFW profile\n",
    "\n",
    "##Here we append all the variables in asingle array.\n",
    "p0 = np.append(ml_init, beta_init)\n",
    "p0 = np.append(p0,[inc_init, log_mbh_init, qDM_init, log_rho_s_init])\n",
    "\n",
    "\"\"\"\n",
    "  We will start all walkers in a large gaussian ball around the values above. \n",
    "  There is no reason for that, beside the fact that we expect a smooth behaviour of the parameters.  \n",
    "\"\"\"\n",
    "p0_std = np.abs(p0*0.5)                                  #0.5 is the sigma of the Gaussian ball. \n",
    "                                                                #We are using 50% of the initial guesses\n",
    "\n",
    "\n",
    "#Finally we initialize the walkers with a gaussian ball around the best Collet's fit.\n",
    "nwalkers = 200                                                  #Number of walkers\n",
    "pos = emcee.utils.sample_ball(p0, p0_std, nwalkers)             #Initial position of all walkers\n",
    "\n",
    "\n",
    "nwalkers, ndim = pos.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backup\n",
    "filename = \"Jam_Emcee_15Parameters.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We save the results in two tables. \n",
    "    The first marks the number of iterations, the mean acceptance fraction an the running time. \n",
    "    The second marks the last fit values for each parameter.\n",
    "\"\"\"\n",
    "np.savetxt('Output_LogFile.txt', np.column_stack([0, 0, 0]),\n",
    "                            fmt=b'\t%i\t %e\t\t\t %e\t ', \n",
    "                            header=\"Output table for the combined model: Dynamic.\\n Iteration\t Mean acceptance fraction\t Processing Time\")\n",
    "\n",
    "np.savetxt(\"LastFit.txt\", np.column_stack([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), \n",
    "fmt=b'%e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t', \n",
    "header=\"Iteration\t ML0\t Delta\t Lower\t b1\t b2\t b3\t b4\t b5\t b6\t b7\t b8\t Inc\t  LogMBH\t qDM\t Logrho_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers in this job: 4\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/home/carlos/anaconda3/lib/python3.7/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "  0%|          | 5/50000 [00:46<130:11:57,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5bad0e782e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mglobal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Only check convergence every 100 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0;31m# Propose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/emcee/moves/red_blue.py\u001b[0m in \u001b[0;36mpropose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Compute the lnprobs of the proposed position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mnew_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Loop over the walkers and update them accordingly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mmap_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             results = list(\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mmap_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             )\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Pool(4) as pool:\n",
    "    #Print the number os cores/workers\n",
    "    print(\"Workers in this job:\", pool._processes)\n",
    "    print(\"Start\")\n",
    "\n",
    "    #Initialize the sampler\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, pool=pool, backend=backend)\n",
    "    \n",
    "    nsteps = 50000\n",
    "\n",
    "     # We'll track how the average autocorrelation time estimate changes\n",
    "    index = 0\n",
    "    autocorr = np.empty(nsteps)\n",
    "\n",
    "     # This will be useful to testing convergence\n",
    "    old_tau = np.inf\n",
    "\n",
    "    # Now we'll sample for up to max_n steps\n",
    "    start = time.time()\n",
    "    global_time = time.time()\n",
    "    for sample in sampler.sample(pos, iterations=nsteps, progress=True):\n",
    "        # Only check convergence every 100 steps\n",
    "        if sampler.iteration % 100:\n",
    "            continue\n",
    "        print(\"\\n\")\n",
    "        print(\"##########################\")\n",
    "        # Compute the autocorrelation time so far\n",
    "        # Using tol=0 means that we'll always get an estimate even\n",
    "        # if it isn't trustworthy\n",
    "        tau = sampler.get_autocorr_time(tol=0)\n",
    "        autocorr[index] = np.mean(tau)\n",
    "        index += 1\n",
    "\n",
    "        #Update a table output with acceptance\n",
    "        table = np.loadtxt(\"Output_LogFile.txt\")\n",
    "\n",
    "        iteration = sampler.iteration\n",
    "        accept = np.mean(sampler.acceptance_fraction)\n",
    "        total_time = time.time() - global_time\n",
    "        upt = np.column_stack([iteration, accept, total_time])\n",
    "\n",
    "        np.savetxt('Output_LogFile.txt', np.vstack([table, upt]),\n",
    "                                fmt=b'\t%i\t %e\t\t\t %e\t ', \n",
    "                                header=\"Iteration\t Mean acceptance fraction\t Processing Time\")\n",
    "\n",
    "        #Update table output with last best fit\n",
    "        last_fit_table = np.loadtxt(\"LastFit.txt\")\n",
    "        flat_samples = sampler.get_chain(flat=True)\n",
    "        values = []\n",
    "        for i in range(ndim):\n",
    "            mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "            q = np.diff(mcmc)\n",
    "            values.append(mcmc[1])\n",
    "\n",
    "        values = np.array(values)\n",
    "        upt = np.append(iteration, values)\n",
    "\n",
    "        np.savetxt(\"LastFit.txt\",np.vstack([last_fit_table, upt]),\n",
    "        fmt=b'%e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t %e\t', \n",
    "        header=\"Iteration\t ML0\t Delta\t Lower\t b1\t b2\t b3\t b4\t b5\t b6\t b7\t b8\t Inc\t  LogMBH\t qDM\t Logrho_s\")\n",
    " \n",
    "\n",
    "        # Check convergence\n",
    "        converged = np.all(tau * 100 < sampler.iteration)\n",
    "        converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "        if converged:\n",
    "            break\n",
    "        old_tau = tau\n",
    "\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    print('\\n')\n",
    "    print(\"Final\")\n",
    "    multi_time = end - start\n",
    "    print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
